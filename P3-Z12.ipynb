{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import tree\n",
    "from decision_trees import *\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "base_forms = [\"adj\", \"adja\", \"adjc\", \"adjp\", \"adv\", \"burk\", \"depr\", \"ger\", \"conj\", \"comp\", \"num\", \"pact\",\n",
    "               \"pant\", \"pcon\", \"ppas\", \"ppron12\", \"ppron3\", \"pred\", \"prep\", \"siebie\", \"subst\", \"verb\", \"brev\",\n",
    "               \"interj\", \"qub\"]\n",
    "\n",
    "verb_forms = [\"nom\", \"gen\", \"acc\", \"dat\", \"inst\", \"loc\", \"voc\"]\n",
    "\n",
    "raw_form = {\"subst:nom\":0, \"subst:gen\":1, \"subst:acc\":2, \"subst:dat\":3, \"subst:inst\":4, \"subst:loc\":5, \"subst:voc\":6,\n",
    "            \"adj\":7, \"adja\":8, \"adjc\":9, \"adjp\":10, \"adv\":11, \"burk\":12, \"depr\":13, \"ger\":14, \"conj\":15, \"comp\":16, \"num\":17, \"pact\":18,\n",
    "            \"pant\":19, \"pcon\":20, \"ppas\":21, \"ppron12\":22, \"ppron3\":23, \"pred\":24, \"prep\":25, \"siebie\":26, \"verb\":27, \"brev\":28,\n",
    "            \"interj\":29, \"qub\":30, \"null\":31, \"na\":32}\n",
    "\n",
    "empty_form = {\"subst:nom\":0, \"subst:gen\":0, \"subst:acc\":0, \"subst:dat\":0, \"subst:inst\":0, \"subst:loc\":0, \"subst:voc\":0,\n",
    "            \"adj\":0, \"adja\":0, \"adjc\":0, \"adjp\":0, \"adv\":0, \"burk\":0, \"depr\":0, \"ger\":0, \"conj\":0, \"comp\":0, \"num\":0, \"pact\":0,\n",
    "            \"pant\":0, \"pcon\":0, \"ppas\":0, \"ppron12\":0, \"ppron3\":0, \"pred\":0, \"prep\":0, \"siebie\":0, \"verb\":0, \"brev\":0,\n",
    "            \"interj\":0, \"qub\":0, \"target\":0}\n",
    "\n",
    "\n",
    "signs = ['.', '(', ')', ';', '\"', '[', ']', ',', '?', '!', ':', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "polish = [('ź', 'z'), ('ż', 'z'), ('ą', 'a'), ('ę', 'e'), ('ó', 'o'), ('ł', 'l'), ('ć', 'c'), ('ń', 'n'), ('ś', 's')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '(', ')', ';', '\"', '[', ']', ',', '?', '!', ':', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "print(signs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ź', 'z'), ('ż', 'z'), ('ą', 'a'), ('ę', 'e'), ('ó', 'o'), ('ł', 'l'), ('ć', 'c'), ('ń', 'n'), ('ś', 's')]\n"
     ]
    }
   ],
   "source": [
    "print(polish)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(line):\n",
    "    line2 = []\n",
    "    line = line.split(' ')\n",
    "    for base in line:\n",
    "        base = base.lower()\n",
    "        for sign in signs:\n",
    "            base = base.replace(sign, ' ')\n",
    "        base = base.strip()\n",
    "        base = base.split(' ')\n",
    "        if base != '' and base != ['']:\n",
    "            line2.extend(base)\n",
    "\n",
    "    return line2\n",
    "\n",
    "\n",
    "def remove_polish(line):\n",
    "    line2 = []\n",
    "    for word in line:\n",
    "        for sign in polish:\n",
    "            word = word.replace(sign[0], sign[1])\n",
    "        line2.append(word)\n",
    "    return line2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_big(line):\n",
    "    line2 = []\n",
    "    line = line.split(' ')\n",
    "    for base in line:\n",
    "        for sign in signs:\n",
    "            base = base.replace(sign, ' ')\n",
    "        base = base.strip()\n",
    "        base = base.split(' ')\n",
    "        if base != '' and base != ['']:\n",
    "            line2.extend(base)\n",
    "\n",
    "    return line2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_polimorph(file='polimorfologik-2.1.txt'):\n",
    "    dictionary = {}\n",
    "    with open(file, 'r', encoding='utf8') as base_file:\n",
    "        for line in base_file:\n",
    "            line = line.strip().lower()\n",
    "            line = line.split(\";\")\n",
    "            line[2] = line[2].split(\"+\")\n",
    "            nl = []\n",
    "            for comp in line[2]:\n",
    "                spl = comp.split(\":\")\n",
    "                if spl[0] != \"subst\":\n",
    "                    if spl[0] not in nl:\n",
    "                        nl.append(spl[0])\n",
    "                else:\n",
    "                    if spl[0] + \":\" + spl[2] not in nl:\n",
    "                        nl.append(spl[0] + \":\" + spl[2])\n",
    "            line[2] = nl\n",
    "            dictionary[line[1]] = (line[0], line[2])\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def create_casts(base_poli):\n",
    "    dictionary = {}\n",
    "    for key in base_poli:\n",
    "        weak_key = remove_polish([key])[0]\n",
    "        if weak_key not in dictionary:\n",
    "            dictionary[weak_key] = []\n",
    "        dictionary[weak_key].append(key)\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_polimorph2(file='polimorfologik-2.1.txt'):\n",
    "    dictionary = {}\n",
    "    with open(file, 'r', encoding='utf8') as base_file:\n",
    "        for line in base_file:\n",
    "            line = line.strip()\n",
    "            line = line.split(\";\")\n",
    "            if line[1].lower() != line[1]:\n",
    "                dictionary[line[1].lower()] = line[1]\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unigrams(file='1grams'):\n",
    "    dictionary = {}\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            line = line.strip().lower()\n",
    "            line = line.split(' ')\n",
    "            dictionary[line[1]] = int(line[0])\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def load_2grams(file='2grams', k=5):\n",
    "    dictionary = {}\n",
    "    i = 0\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            line = line.strip().lower()\n",
    "            line = line.split(' ')\n",
    "            if int(line[0]) >= k:\n",
    "                if line[1] not in dictionary:\n",
    "                    dictionary[line[1]] = {}\n",
    "                dictionary[line[1]][line[2]] = int(line[0])\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def load_3grams(file='3grams', k=5):\n",
    "    dictionary = {}\n",
    "    i = 0\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            line = line.strip().lower()\n",
    "            line = line.split(' ')\n",
    "            if int(line[0]) >= k:\n",
    "                if line[1] not in dictionary:\n",
    "                    dictionary[line[1]] = {}\n",
    "                dictionary[line[1]][line[2:]] = int(line[0])\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_set(file='train_shuf.txt', k=10000):\n",
    "    i = 0\n",
    "    lines = []\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            if i == k:\n",
    "                break\n",
    "            lines.append(tokenize(line))\n",
    "            i += 1\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def divide_set(total_set, k=0.7):\n",
    "    s = round(len(total_set)*k)\n",
    "    return total_set[:s], total_set[s:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_big_set(file='train_shuf.txt', k=10000):\n",
    "    i = 0\n",
    "    lines = []\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            if i == k:\n",
    "                break\n",
    "            lines.append(tokenize_big(line))\n",
    "            i += 1\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(listt):\n",
    "        a = []\n",
    "        for itemm in listt:\n",
    "            if isinstance(itemm, list):\n",
    "                a += flatten(itemm)\n",
    "            else:\n",
    "                a.append(itemm)\n",
    "        return a\n",
    "\n",
    "def combine(lines):\n",
    "    conc = lines[0]\n",
    "    if len(lines) == 1:\n",
    "        conc = [conc]\n",
    "    for part in lines[1:]:\n",
    "        conc = list(map(list, itertools.product(conc, part)))\n",
    "    conc2 = []\n",
    "    for item in conc:\n",
    "        conc2.append(flatten(item))\n",
    "    return conc2\n",
    "\n",
    "def permute(line, casts):\n",
    "    line2 = []\n",
    "    for word in line:\n",
    "        if word in casts:\n",
    "            line2.append(casts[word])\n",
    "        else:\n",
    "            line2.append([word])\n",
    "\n",
    "    return combine(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[[None, None], ['a', None]]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine([[None, \"a\"], [None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong(line, casts):\n",
    "    if line not in permute(line, casts):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(line, k=3):\n",
    "    \n",
    "    line2 = []\n",
    "    line2.append(None)\n",
    "    line2 += line\n",
    "    line2.append(None)\n",
    "    line = line2\n",
    "    \n",
    "    if len(line) < k:\n",
    "        line2 = []\n",
    "        for i in range(math.ceil((k-len(line))/2)):\n",
    "            line2.append(None)\n",
    "        line2 += line\n",
    "        for i in range(math.floor((k-len(line))/2)):\n",
    "            line2.append(None)\n",
    "        line = line2\n",
    "        \n",
    "    if len(line) == k:\n",
    "        return [line]\n",
    "    \n",
    "    else:\n",
    "        lines = []\n",
    "        line2 = line[0:k]\n",
    "        lines.append(line2.copy())\n",
    "        for word in line[k:]:\n",
    "            del line2[0]\n",
    "            line2.append(word)\n",
    "            lines.append(line2.copy())\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dgrams(training_set, casts):\n",
    "    dgrams = {}\n",
    "    for line in training_set:\n",
    "        if len(line) >= 2:\n",
    "            fst = line[0]\n",
    "            for word in line[1:]:\n",
    "                snd = word\n",
    "                if not wrong([fst, snd], casts):\n",
    "                    if fst not in dgrams:\n",
    "                        dgrams[fst] = {}\n",
    "                    if snd not in dgrams[fst]:\n",
    "                        dgrams[fst][snd] = 0\n",
    "                    dgrams[fst][snd] += 1\n",
    "                fst = snd\n",
    "    \n",
    "    return dgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(training_set, poli, casts, digrams1, digrams2):\n",
    "    # df = pd.DataFrame(data=raw_form)\n",
    "    # duos = pd.DataFrame(data={\"fst\":[], \"snd\":[], \"target\":[]})\n",
    "    # trios = pd.DataFrame(data={\"fst\":[], \"snd\":[], \"trd\":[], \"target\":[]})\n",
    "    trios = []\n",
    "    j = -1\n",
    "    for base_line in training_set:\n",
    "        j += 1\n",
    "        if j % 10000 == 0:\n",
    "            print(j)\n",
    "\n",
    "        for line in windows(base_line, k=3):\n",
    "            if not wrong(line, casts):\n",
    "                for perm in permute(line, casts):\n",
    "                    trio = {\"fst\":0, \"snd\":0, \"trd\":0, \"lgram\":0, \"rgram\":0, \"target\":0}\n",
    "                    \n",
    "                    if line == perm:\n",
    "                        trio[\"target\"] = \"y\"\n",
    "                    else:\n",
    "                        trio[\"target\"] = \"n\"\n",
    "                        \n",
    "                    #if perm[0] in digrams1:\n",
    "                    #    if perm[1] in digrams1[perm[0]]:\n",
    "                    #        trio[\"lgram\"] = \"y\"\n",
    "                    #if perm[0] in digrams2:\n",
    "                    #    if perm[1] in digrams2[perm[0]]:\n",
    "                    #        trio[\"lgram\"] = \"y\"\n",
    "                    #if perm[1] in digrams1:\n",
    "                    #    if perm[2] in digrams1[perm[1]]:\n",
    "                    #        trio[\"rgram\"] = \"y\"\n",
    "                    #if perm[1] in digrams2:\n",
    "                    #    if perm[2] in digrams2[perm[1]]:\n",
    "                    #        trio[\"rgram\"] = \"y\"\n",
    "                    \n",
    "                    pres = 0\n",
    "                    size = 1\n",
    "                    if perm[0] in digrams1:\n",
    "                        if perm[1] in digrams1[perm[0]]:\n",
    "                            pres += digrams1[perm[0]][perm[1]]\n",
    "                        size += digrams1[perm[0]][0]\n",
    "                    if perm[0] in digrams2:\n",
    "                        if perm[1] in digrams2[perm[0]]:\n",
    "                            pres += digrams2[perm[0]][perm[1]]\n",
    "                        size += digrams2[perm[0]][0]\n",
    "                    sc1 = (pres/size) * math.log(size)\n",
    "                    trio[\"lgram\"] = round(sc1*100)/100\n",
    "                    \n",
    "                    pres = 0\n",
    "                    size = 1\n",
    "                    if perm[1] in digrams1:\n",
    "                        if perm[2] in digrams1[perm[1]]:\n",
    "                            pres += digrams1[perm[1]][perm[2]]\n",
    "                        size += digrams1[perm[1]][0]\n",
    "                    if perm[1] in digrams2:\n",
    "                        if perm[2] in digrams2[perm[1]]:\n",
    "                            pres += digrams2[perm[1]][perm[2]]\n",
    "                        size += digrams2[perm[1]][0]\n",
    "                    sc1 = (pres/size) * math.log(size)\n",
    "                    trio[\"rgram\"] = round(sc1*100)/100\n",
    "                    \n",
    "                    form = []\n",
    "                    bad = False\n",
    "                    for word in perm:\n",
    "                        if word in poli:\n",
    "                            form.append(poli[word][1])\n",
    "                        else:\n",
    "                            if word == None:\n",
    "                                form.append([\"null\"])\n",
    "                            else:\n",
    "                                form.append([\"na\"])\n",
    "                    \n",
    "                    if not bad:\n",
    "                        form = combine(form)\n",
    "                        for comb in form:\n",
    "                            trio2 = trio.copy()\n",
    "                            trio2[\"fst\"] = comb[0]\n",
    "                            trio2[\"snd\"] = comb[1]\n",
    "                            trio2[\"trd\"] = comb[2]\n",
    "                            trios.append(trio2)\n",
    "\n",
    "    triosdt = pd.DataFrame(trios)\n",
    "    y = []\n",
    "    x = []\n",
    "    for trio in trios:\n",
    "        y.append(trio[\"target\"])\n",
    "        del trio[\"target\"]\n",
    "        x.append([])\n",
    "        for key in trio:\n",
    "            if key == \"fst\" or key == \"snd\" or key == \"trd\":\n",
    "                x[-1].append(raw_form[trio[key]])\n",
    "            else:\n",
    "                x[-1].append(trio[key])\n",
    "    \n",
    "    return triosdt, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_big(training_set):\n",
    "    dictionary = {}\n",
    "    for line in training_set:\n",
    "        if len(line) >= 2:\n",
    "            for word in line[1:]:\n",
    "                if len(word) > 0:\n",
    "                    if word[0].lower() != word[0]:\n",
    "                        if word.lower() not in dictionary:\n",
    "                            dictionary[word.lower()] = [word, 0, 0]\n",
    "                        dictionary[word.lower()][1] += 1\n",
    "                        dictionary[word.lower()][2] += 1\n",
    "                    else:\n",
    "                        if word in dictionary:\n",
    "                            dictionary[word][2] += 1\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_digrams(digrams):\n",
    "    for fst in digrams:\n",
    "        count = 0\n",
    "        for snd in digrams[fst]:\n",
    "            count += digrams[fst][snd]\n",
    "        digrams[fst][0] = count\n",
    "    return digrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_polish2(phrase, casts, digrams1, digrams2):\n",
    "    perms = []\n",
    "    i = 0\n",
    "    for line in windows(phrase, k=2):\n",
    "        perms.append([])\n",
    "        for perm in permute(line, casts):\n",
    "            pres = 0\n",
    "            size = 1\n",
    "            if perm[0] in digrams1:\n",
    "                if perm[1] in digrams1[perm[0]]:\n",
    "                    pres += digrams1[perm[0]][perm[1]]\n",
    "                size += digrams1[perm[0]][0]\n",
    "            if perm[0] in digrams2:\n",
    "                if perm[1] in digrams2[perm[0]]:\n",
    "                    pres += digrams2[perm[0]][perm[1]]\n",
    "                size += digrams2[perm[0]][0]\n",
    "            score = (pres/size) * math.log(size)\n",
    "            perms[i].append((perm,score))\n",
    "        i += 1\n",
    "    \n",
    "    output = []\n",
    "    prev = None\n",
    "    for i in range(len(perms)):\n",
    "        mx = -1\n",
    "        mperm = None\n",
    "        for perm, sc in perms[i]:\n",
    "            if perm[0] == prev:\n",
    "                if sc > mx:\n",
    "                    mx = sc\n",
    "                    mperm = perm\n",
    "        output.append(mperm[1])\n",
    "        prev = mperm[1]           \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_polish(phrase, poli, casts, digrams1, digrams2, main_tree):\n",
    "    ans = {}\n",
    "    for i in range(len(phrase)+2):\n",
    "        ans[i] = []\n",
    "    \n",
    "    perms = []\n",
    "    i = 0\n",
    "    for line in windows(phrase, k=3):\n",
    "        perms.append([])\n",
    "        i += 1\n",
    "        mx = 0\n",
    "        mn = 0\n",
    "        mxperm = line\n",
    "        for perm in permute(line, casts):          \n",
    "            entry = {\"fst\":0, \"snd\":0, \"trd\":0, \"lgram\":\"n\", \"rgram\":\"n\"}\n",
    "            #if perm[0] in digrams1:\n",
    "            #    if perm[1] in digrams1[perm[0]]:\n",
    "            #        entry[\"lgram\"] = \"y\"\n",
    "            #if perm[0] in digrams2:\n",
    "            #    if perm[1] in digrams2[perm[0]]:\n",
    "            #        entry[\"lgram\"] = \"y\"\n",
    "            #if perm[1] in digrams1:\n",
    "            #    if perm[2] in digrams1[perm[1]]:\n",
    "            #        entry[\"rgram\"] = \"y\"\n",
    "            #if perm[1] in digrams2:\n",
    "            #    if perm[2] in digrams2[perm[1]]:\n",
    "            #        entry[\"rgram\"] = \"y\"\n",
    "            pres = 0\n",
    "            size = 1\n",
    "            if perm[0] in digrams1:\n",
    "                if perm[1] in digrams1[perm[0]]:\n",
    "                    pres += digrams1[perm[0]][perm[1]]\n",
    "                size += digrams1[perm[0]][0]\n",
    "            if perm[0] in digrams2:\n",
    "                if perm[1] in digrams2[perm[0]]:\n",
    "                    pres += digrams2[perm[0]][perm[1]]\n",
    "                size += digrams2[perm[0]][0]\n",
    "            sc1 = (pres/size) * math.log(size)\n",
    "            entry[\"lgram\"] = round(sc1*100)/100   \n",
    "\n",
    "            pres = 0\n",
    "            size = 1\n",
    "            if perm[1] in digrams1:\n",
    "                if perm[2] in digrams1[perm[1]]:\n",
    "                    pres += digrams1[perm[1]][perm[2]]\n",
    "                size += digrams1[perm[1]][0]\n",
    "            if perm[1] in digrams2:\n",
    "                if perm[2] in digrams2[perm[1]]:\n",
    "                    pres += digrams2[perm[1]][perm[2]]\n",
    "                size += digrams2[perm[1]][0]\n",
    "            sc1 = (pres/size) * math.log(size)\n",
    "            entry[\"rgram\"] = round(sc1*100)/100 \n",
    "                    \n",
    "            forms = []\n",
    "            for word in perm:\n",
    "                if word in poli:\n",
    "                    forms.append(poli[word][1])\n",
    "                else:\n",
    "                    if word == None:\n",
    "                        forms.append([\"null\"])\n",
    "                    else:\n",
    "                        forms.append([\"na\"])\n",
    "\n",
    "            forms = combine(forms)\n",
    "            \n",
    "            #mn1 = 1\n",
    "            #mx1 = 0\n",
    "            ttl = 0\n",
    "            for form in forms:\n",
    "                entry[\"fst\"] = form[0]\n",
    "                entry[\"snd\"] = form[1]\n",
    "                entry[\"trd\"] = form[2]\n",
    "                sc1 = main_tree.classify(entry)\n",
    "                #print(perm)\n",
    "                #print(entry, score)\n",
    "                ttl += sc1*sc1\n",
    "                #if sc1 > mx1:\n",
    "                #    mx1 = sc1\n",
    "                #if sc1 < mn1:\n",
    "                #    mn1 = sc1\n",
    "            #if 0.5 - mn1 >= mx1 - 0.5:\n",
    "            #    entry[\"trio\"] = mn1\n",
    "            #else:\n",
    "            #    entry[\"trio\"] = mx1\n",
    "            sc1 = ttl/len(forms)\n",
    "            perms[i-1].append((perm, sc1))\n",
    "            if sc1 > mx:\n",
    "                mx = sc1\n",
    "                mperm = perm\n",
    "                \n",
    "\n",
    "        #ans[i-1].append((mperm[0], mx))\n",
    "        #ans[i].append((mperm[1], mx))\n",
    "        #ans[i+1].append((mperm[2], mx))\n",
    "\n",
    "    output = []\n",
    "    prev = None\n",
    "    for i in range(len(perms)):\n",
    "        mx = -1\n",
    "        mperm = None\n",
    "        for perm, sc in perms[i]:\n",
    "            if perm[0] == prev:\n",
    "                if sc > mx:\n",
    "                    mx = sc\n",
    "                    mperm = perm\n",
    "        output.append(mperm[1])\n",
    "        prev = mperm[1]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_polishF(phrase, poli, casts, digrams1, digrams2, main_tree):\n",
    "    ans = {}\n",
    "    for i in range(len(phrase)+2):\n",
    "        ans[i] = []\n",
    "    \n",
    "    perms = []\n",
    "    i = 0\n",
    "    for line in windows(phrase, k=3):\n",
    "        perms.append([])\n",
    "        i += 1\n",
    "        mx = 0\n",
    "        mn = 0\n",
    "        mxperm = line\n",
    "        for perm in permute(line, casts):          \n",
    "            entry = {\"fst\":0, \"snd\":0, \"trd\":0, \"lgram\":\"n\", \"rgram\":\"n\"}\n",
    "            \n",
    "            pres = 0\n",
    "            size = 1\n",
    "            if perm[0] in digrams1:\n",
    "                if perm[1] in digrams1[perm[0]]:\n",
    "                    pres += digrams1[perm[0]][perm[1]]\n",
    "                size += digrams1[perm[0]][0]\n",
    "            if perm[0] in digrams2:\n",
    "                if perm[1] in digrams2[perm[0]]:\n",
    "                    pres += digrams2[perm[0]][perm[1]]\n",
    "                size += digrams2[perm[0]][0]\n",
    "            sc1 = (pres/size) * math.log(size)\n",
    "            entry[\"lgram\"] = round(sc1*100)/100   \n",
    "\n",
    "            pres = 0\n",
    "            size = 1\n",
    "            if perm[1] in digrams1:\n",
    "                if perm[2] in digrams1[perm[1]]:\n",
    "                    pres += digrams1[perm[1]][perm[2]]\n",
    "                size += digrams1[perm[1]][0]\n",
    "            if perm[1] in digrams2:\n",
    "                if perm[2] in digrams2[perm[1]]:\n",
    "                    pres += digrams2[perm[1]][perm[2]]\n",
    "                size += digrams2[perm[1]][0]\n",
    "            sc1 = (pres/size) * math.log(size)\n",
    "            entry[\"rgram\"] = round(sc1*100)/100 \n",
    "                    \n",
    "            forms = []\n",
    "            for word in perm:\n",
    "                if word in poli:\n",
    "                    forms.append(poli[word][1])\n",
    "                else:\n",
    "                    if word == None:\n",
    "                        forms.append([\"null\"])\n",
    "                    else:\n",
    "                        forms.append([\"na\"])\n",
    "\n",
    "            forms = combine(forms)\n",
    "            \n",
    "            ttl = 0\n",
    "            for form in forms:\n",
    "                entry[\"fst\"] = form[0]\n",
    "                entry[\"snd\"] = form[1]\n",
    "                entry[\"trd\"] = form[2]\n",
    "                fentry = []\n",
    "                for key in entry:\n",
    "                    if key == \"fst\" or key == \"snd\" or key == \"trd\":\n",
    "                        fentry.append(raw_form[entry[key]])\n",
    "                    else:\n",
    "                        fentry.append(entry[key])\n",
    "                sc1 = main_tree.predict_proba([fentry])[0][1]\n",
    "                ttl += sc1*sc1\n",
    "\n",
    "            sc1 = ttl/len(forms)\n",
    "            perms[i-1].append((perm, sc1))\n",
    "            if sc1 > mx:\n",
    "                mx = sc1\n",
    "                mperm = perm\n",
    "\n",
    "    output = []\n",
    "    prev = None\n",
    "    for i in range(len(perms)):\n",
    "        mx = -1\n",
    "        mperm = None\n",
    "        for perm, sc in perms[i]:\n",
    "            if perm[0] == prev:\n",
    "                if sc > mx:\n",
    "                    mx = sc\n",
    "                    mperm = perm\n",
    "        output.append(mperm[1])\n",
    "        prev = mperm[1]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_case(phrase, bigs1, bigs2):\n",
    "    ww = phrase[0]\n",
    "    fixed = []\n",
    "    fixed.append(ww.capitalize())\n",
    "    if len(phrase) >= 2:\n",
    "        for word in phrase[1:]:\n",
    "            if word in bigs1 and (word not in bigs2 or (word in bigs2 and bigs2[word][1] / bigs2[word][2] >= 0.5)):\n",
    "                fixed.append(bigs1[word])\n",
    "            else:\n",
    "                if word in bigs2 and bigs2[word][1] / bigs2[word][2] > 0.5:\n",
    "                    fixed.append(bigs2[word][0])\n",
    "                else:\n",
    "                    fixed.append(word)\n",
    "    \n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(phrase1, phrase2):\n",
    "    s = 0\n",
    "    for i in range(len(phrase1)):\n",
    "        if phrase1[i] == phrase2[i]:\n",
    "            s += 1\n",
    "\n",
    "    return s/len(phrase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gpoli = load_polimorph()\n",
    "Gcasts = create_casts(Gpoli)\n",
    "#unigramsS = load_unigrams()\n",
    "Gdigrams1 = load_2grams(k=3)\n",
    "#trigramsS = load_3grams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gbig = load_polimorph2()\n",
    "\n",
    "Gtotal_set = load_big_set(k=100000)\n",
    "Gbig2 = find_big(Gtotal_set)\n",
    "del Gtotal_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gtotal_set = load_set(k=100000)\n",
    "Gdigrams2 = create_dgrams(Gtotal_set, Gcasts)\n",
    "del Gtotal_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "           fst        snd   trd  lgram  rgram target\n",
      "0         null  subst:gen    na   0.00   0.00      y\n",
      "1    subst:gen         na  verb   0.00   0.35      y\n",
      "2           na       verb  verb   0.35   0.00      y\n",
      "3         verb       verb   adv   0.00   0.07      y\n",
      "4         verb       verb   num   0.00   0.07      y\n",
      "..         ...        ...   ...    ...    ...    ...\n",
      "247  subst:gen       prep  verb   0.44   0.00      y\n",
      "248     interj        ger  null   0.00   0.00      y\n",
      "249     interj       verb  null   0.00   0.00      y\n",
      "250       prep        ger  null   0.00   0.00      y\n",
      "251       prep       verb  null   0.00   0.00      y\n",
      "\n",
      "[252 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(create_database(load_set(k=3), Gpoli, Gcasts, Gdigrams1, Gdigrams2)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gvalidation_set = load_set(k=1200000)[1000000:]\n",
    "Gvalidation_set2 = load_big_set(k=1200000)[1000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gdigrams1 = count_digrams(Gdigrams1)\n",
    "Gdigrams2 = count_digrams(Gdigrams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roli': 46, 'wysokości.': 28, 'linii': 22, 'wysokości': 22, 'roli:': 21, 'ciągłej': 18, 'wagi': 17, 'większości': 16, 'roli.': 15, 'wartości': 13, 'roli,': 12, 'spirali': 12, 'moralności,': 11, 'helisy': 9, 'i': 9, 'moralności': 9, 'w': 9, 'moralności.': 8, 'składki': 8, 'z': 8, 'ilości': 7, 'kobiet': 7, 'przewadze,': 7, 'wysokości,': 7, 'helisy,': 6, 'para': 6, 'przewadze': 6, 'ulgi': 6, '-': 5, 'lojalności.': 5, 'warstwy': 5, 'większości,': 5, 'większości.': 5, 'helisy.': 4, 'koronie.': 4, 'monarchii.': 4, 'natury.': 4, 'negacji.': 4, 'przewadze.': 4, 'tożsamości': 4, 'wygranej': 4, 'ciągłej.': 3, 'dokumentacji': 3, 'dziewcząt': 3, 'gry,': 3, 'ilości.': 3, 'juniorek,': 3, 'juniorów': 3, 'katalizy': 3, 'kobiet:': 3, 'korony': 3, 'lojalności,': 3, 'lub': 3, 'mariusz': 3, 'miary': 3, 'miary,': 3, 'moralności:': 3, 'odpowiedzialności': 3, 'opłaty': 3, 'pętli': 3, 'platynowej': 3, 'podłodze': 3, 'postaci': 3, 'razem': 3, 'składki.': 3, 'stawki': 3, 'szerokości': 3, 'ściany': 3, 'tożsamości.': 3, 'wraz': 3, 0: 509}\n"
     ]
    }
   ],
   "source": [
    "print(Gdigrams1[\"podwójnej\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "Gtrain_set = load_set(k=1000)\n",
    "print(len(Gtrain_set))\n",
    "\n",
    "Gdatabase, _, _ = create_database(Gtrain_set, Gpoli, Gcasts, Gdigrams1, Gdigrams2)\n",
    "del Gtrain_set\n",
    "\n",
    "Gmain_tree = Tree(Gdatabase)\n",
    "del Gdatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=4, n_jobs=6,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gtrain_set = load_set(k=200000)\n",
    "\n",
    "_, X, y = create_database(Gtrain_set, Gpoli, Gcasts, Gdigrams1, {})\n",
    "del Gtrain_set\n",
    "\n",
    "Gmain_tree2 = RandomForestClassifier(max_depth=4, random_state=0, criterion=\"entropy\", n_jobs=6)\n",
    "Gmain_tree2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2162131 , 0.7837869 ],\n",
       "       [0.1489218 , 0.8510782 ],\n",
       "       [0.16304982, 0.83695018],\n",
       "       [0.18159669, 0.81840331],\n",
       "       [0.18163694, 0.81836306]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gtrain_set = load_set(k=2)\n",
    "\n",
    "_, X, y = create_database(Gtrain_set, Gpoli, Gcasts, Gdigrams1, Gdigrams2)\n",
    "del Gtrain_set\n",
    "\n",
    "Gmain_tree2.predict_proba(X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "Gtrain_set = load_set(k=120000)[100000:]\n",
    "trios2, _, _ = create_database(Gtrain_set, Gpoli, Gcasts, Gdigrams1, Gdigrams2)\n",
    "del Gtrain_set\n",
    "Gmain_tree.start_prune(trios2)\n",
    "del trios2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test-output\\\\database_tree.gv.pdf'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gmain_tree.draw().render('test-output/database_tree.gv', view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parlament', 'zdecydował', 'jednak', 'inaczej', 'i', 'przyjął', 'w', 'ustawie', 'z', 'dnia', 'r', 'jednoinstancyjne', 'postepowanie', 'orzeczniczo-lekarskie']\n",
      "['parlament', 'zdecydował', 'jednak', 'inaczej', 'i', 'przyjął', 'w', 'ustawie', 'z', 'dnia', 'r', 'jednoinstancyjne', 'postępowanie', 'orzeczniczo-lekarskie']\n",
      "['parlament', 'zdecydowal', 'jednak', 'inaczej', 'i', 'przyjal', 'w', 'ustawie', 'z', 'dnia', 'r', 'jednoinstancyjne', 'postepowanie', 'orzeczniczo-lekarskie']\n",
      "0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "line = load_set(k=3)[1]\n",
    "print(fix_polish(remove_polish(line), Gpoli, Gcasts, Gdigrams1, Gdigrams2, Gmain_tree))\n",
    "print(line)\n",
    "print(remove_polish(line))\n",
    "print(score(line, fix_polish(remove_polish(line), Gpoli, Gcasts, Gdigrams1, Gdigrams2, Gmain_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "0.9346142255902423\n"
     ]
    }
   ],
   "source": [
    "#k=20000, base decision tree\n",
    "k = 100\n",
    "total = 0\n",
    "for i in range(k):\n",
    "    line = Gvalidation_set[i]\n",
    "    line2 = Gvalidation_set2[i]\n",
    "    broken_line = remove_polish(line)\n",
    "    fixed_line = fix_polish(broken_line, Gpoli, Gcasts, Gdigrams1, Gdigrams2, Gmain_tree)\n",
    "    sc1 = score(line, fixed_line)\n",
    "    fixed_line2 = fix_case(fixed_line, Gbig, Gbig2)\n",
    "    sc2 = score(line2, fixed_line2)\n",
    "    total += math.sqrt(sc1*sc1)\n",
    "\n",
    "print(total/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625769088763515\n"
     ]
    }
   ],
   "source": [
    "#k=100000, random forest\n",
    "k = 1000\n",
    "total = 0\n",
    "for i in range(k):\n",
    "    line = Gvalidation_set[i]\n",
    "    line2 = Gvalidation_set2[i]\n",
    "    broken_line = remove_polish(line)\n",
    "    fixed_line = fix_polishF(broken_line, Gpoli, Gcasts, Gdigrams1, Gdigrams2, Gmain_tree2)\n",
    "    sc1 = score(line, fixed_line)\n",
    "    fixed_line2 = fix_case(fixed_line, Gbig, Gbig2)\n",
    "    sc2 = score(line2, fixed_line2)\n",
    "    total += math.sqrt(sc1*sc2)\n",
    "\n",
    "print(total/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9687744539404973\n"
     ]
    }
   ],
   "source": [
    "#just use grams lol\n",
    "k = 1000\n",
    "total = 0\n",
    "for i in range(k):\n",
    "    line = Gvalidation_set[i]\n",
    "    line2 = Gvalidation_set2[i]\n",
    "    broken_line = remove_polish(line)\n",
    "    fixed_line = fix_polish2(broken_line, Gcasts, Gdigrams1, Gdigrams2)\n",
    "    sc1 = score(line, fixed_line)\n",
    "    fixed_line2 = fix_case(fixed_line, Gbig, Gbig2)\n",
    "    sc2 = score(line2, fixed_line2)\n",
    "    total += math.sqrt(sc1*sc2)\n",
    "\n",
    "print(total/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 3077, 607097]\n"
     ]
    }
   ],
   "source": [
    "print(Gbig2[\"w\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 21, 'dużo': 17, 'na': 16, '-': 12, 'za': 11, 'z': 8, 'tak': 7, 'alkoholu': 6, 'do': 6, 'wodę': 6, 'już': 5, 'mleko': 5, 'mleko,': 5, 'pij': 5, 'w': 5}\n"
     ]
    }
   ],
   "source": [
    "print(Gdigrams1[\"pij\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'świeżo': 1, 'wodę': 1, 'piotrek-elektryczne': 1, 'tylko': 1, 'nych': 1, 'skim': 1, 'i': 1, 'na': 1}\n"
     ]
    }
   ],
   "source": [
    "print(Gdigrams2[\"pij\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'świeżo': 1, 'wodę': 1, 'piotrek-elektryczne': 1, 'tylko': 1, 'nych': 1, 'skim': 1, 'i': 1, 'na': 1}\n"
     ]
    }
   ],
   "source": [
    "print(Gdigrams2[\"pij\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jeśli']\n"
     ]
    }
   ],
   "source": [
    "print(Gcasts[\"jesli\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}